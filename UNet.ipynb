{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # or \"jax\" or \"torch\"\n",
    "import tensorflow.keras as keras\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architektur\n",
    "Die U Net Modelarchitektur, wie der Name schon impliziert, ist U-formig angeordnet. \n",
    "\n",
    "## Bestandteile\n",
    "- Convolutions (Blau Pfeile) kernel: 3x3, kein padding, stride: 1\n",
    "- Pooling (rote Pfeile) kernel: 2x2, stride: 2\n",
    "- Up Convolutions (de-convolutions): kernel 2x2\n",
    "- Skip connections (ähnlich zum ResNet)\n",
    "\n",
    "### Dimensionen von den skip connections\n",
    "Die untere Skizze bezeichnet die grauen Pfeile mit \"crop and copy\". Warum nicht nur einfan nur kopieren ? \n",
    "\n",
    "Hint: Dimensionen...\n",
    "\n",
    "Kann man es auch anders lösen, wenn ja wie?\n",
    "\n",
    "## Features\n",
    "- je tiefer in der Architektur desto größer das \"Receptive Field\" (ConvNets)\n",
    "- nur geringer verlust von Information aka low level features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](U-Net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie implementiert man sowas ?\n",
    "Breche die einzelnen Bestandteile in kleinere runter und implementiere zuerst die \"Kleinigkeiten\", arbeite dich somit bis zum vollständigen UNet. \n",
    "-> Bottom up approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Conv2DTranspose, Dropout, Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(num_filters, 3, activation='relu', padding='same')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeLayer(Layer):  # you can easily change this to be a cropping layer\n",
    "    def __init__(self, target_shape, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.resize(x, (self.target_shape[0], self.target_shape[1]))\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)  # deconvolution ...\n",
    "    # Check dimensions and scale skip features if needed\n",
    "    if x.shape[1] != skip_features.shape[1] or x.shape[2] != skip_features.shape[2]:\n",
    "        target_shape = x.shape[1:3]\n",
    "        skip_features = ResizeLayer(target_shape=target_shape)(skip_features)\n",
    "    \n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape, out_classes, activation=\"sigmoid\"):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    b1 = conv_block(p4, 1024)\n",
    "    \n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = Conv2D(out_classes, 1, activation=activation)(d4)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='U-Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET = build_unet((572,572,1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),  # oder dice loss\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET.summary(line_length=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nun mit Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(ConvBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_filters, 3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_filters, 3, activation='relu', padding='same')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.conv = ConvBlock(num_filters)\n",
    "        self.pool = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.up = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')\n",
    "        self.conv = ConvBlock(num_filters)\n",
    "\n",
    "    def call(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        if x.shape[1] != skip.shape[1] or x.shape[2] != skip.shape[2]:\n",
    "            target_shape = x.shape[1:3]\n",
    "            print(x.shape, skip.shape)\n",
    "            skip = ResizeLayer(target_shape=target_shape)(skip)\n",
    "        print(skip.shape)\n",
    "        x = tf.concat([x, skip])\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(UNet, self).__init__(**kwargs)\n",
    "        self.enc1 = EncoderBlock(64)\n",
    "        self.enc2 = EncoderBlock(128)\n",
    "        self.enc3 = EncoderBlock(256)\n",
    "        self.enc4 = EncoderBlock(512)\n",
    "        self.center = ConvBlock(1024)\n",
    "        self.dec4 = DecoderBlock(512)\n",
    "        self.dec3 = DecoderBlock(256)\n",
    "        self.dec2 = DecoderBlock(128)\n",
    "        self.dec1 = DecoderBlock(64)\n",
    "        self.out = tf.keras.layers.Conv2D(num_classes, 1, activation='sigmoid', name=\"outs\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        s1, p1 = self.enc1(inputs)\n",
    "        s2, p2 = self.enc2(p1)\n",
    "        s3, p3 = self.enc3(p2)\n",
    "        s4, p4 = self.enc4(p3)\n",
    "\n",
    "        b1 = self.center(p4)\n",
    "\n",
    "        d4 = self.dec4(b1, s4)\n",
    "        d3 = self.dec3(d4, s3)\n",
    "        d2 = self.dec2(d3, s2)\n",
    "        d1 = self.dec1(d2, s1)\n",
    "\n",
    "        outputs = self.out(d1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(2)\n",
    "unet.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training auf 2 Arten\n",
    "### Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_gen(n=10_000):\n",
    "    \"\"\"\n",
    "    creates a generator for n pictures of shape (572,572,1)\n",
    "    \"\"\" \n",
    "    def gen():\n",
    "        for _ in range(n):\n",
    "            image = np.random.randint(0, 256, size=(572, 572, 1))\n",
    "            label = np.random.randint(0, 1, size=(560, 560, 1))\n",
    "            # schon normalisierte daten ...\n",
    "            image_ = np.random.randn(572, 572, 1) * 255\n",
    "            label_ = np.random.randn(560, 560, 1)\n",
    "            yield image.astype(np.float64), label.astype(np.uint8)\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(n_train, n_val):\n",
    "    train = Dataset.from_generator(\n",
    "        get_sample_gen(n_train),\n",
    "        output_signature=(\n",
    "         tf.TensorSpec(shape=(572, 572, 1), dtype=tf.float64),\n",
    "         tf.TensorSpec(shape=(560, 560, 1), dtype=tf.uint8))\n",
    "    )\n",
    "\n",
    "    validation= Dataset.from_generator(\n",
    "        get_sample_gen(n_val),\n",
    "        output_signature=(\n",
    "         tf.TensorSpec(shape=(572, 572, 1), dtype=tf.float64),\n",
    "         tf.TensorSpec(shape=(560, 560, 1), dtype=tf.uint8))\n",
    "    )\n",
    "\n",
    "    return train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds = create_datasets(N_SAMPLES, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was nun?\n",
    "Was muss mit den Daten __immer__ gemacht werden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "    count = np.int64(0) \n",
    "\n",
    "    sum_, sum_squared_diff = np.float64(0), np.float64(0)\n",
    "    for img, _ in dataset:\n",
    "        y_dim, x_dim, n_chanels = img.shape\n",
    "        sum_ += tf.reduce_sum(img).numpy()\n",
    "        count += x_dim * y_dim * n_chanels\n",
    "    mean = sum_ / count\n",
    "\n",
    "    for img, _ in dataset:\n",
    "        sum_squared_diff += tf.reduce_sum(tf.square(img-mean)).numpy()\n",
    "    std = np.sqrt(sum_squared_diff/count)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = get_mean_std(train_ds)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, mean, std):\n",
    "    return (image - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(lambda image, label: (normalize_image(image, mean, std), label))\n",
    "validation_ds = validation_ds.map(lambda image, label: (normalize_image(image, mean, std), label)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_after, std_train_after = get_mean_std(train_ds)\n",
    "mean_val_after, std_val_after = get_mean_std(validation_ds)\n",
    "print(f\"{mean_train_after=}\\n{std_train_after=}\\n{mean_val_after=}\\n{std_val_after=}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(800).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "validation_ds = validation_ds.shuffle(200).batch(8).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "\n",
    "# UNET.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=validation_ds,\n",
    "#     epochs=5,\n",
    "#     callbacks=[tensorboard_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "loss_fn = keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, labels) in enumerate(train_ds):\n",
    "        print(f'started batch {batch_idx + 1}')\n",
    "        # Open a GradientTape to record the gradients\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = UNET(images, training=True)\n",
    "            loss = loss_fn(labels, predictions)\n",
    "\n",
    "        # Compute the gradients\n",
    "        gradients = tape.gradient(loss, UNET.trainable_variables)\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.apply_gradients(zip(gradients, UNET.trainable_variables))\n",
    "        print(f\"loss in batch {batch_idx + 1}: {loss}\")\n",
    "\n",
    "\n",
    "    # Print the loss for the current epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
