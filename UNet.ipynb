{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\" # or \"jax\" or \"torch\"\n",
    "import tensorflow.keras as keras\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architektur\n",
    "Die U Net Modelarchitektur, wie der Name schon impliziert, ist U-formig angeordnet. \n",
    "\n",
    "## Bestandteile\n",
    "- Convolutions (Blau Pfeile) kernel: 3x3, kein padding, stride: 1\n",
    "- Pooling (rote Pfeile) kernel: 2x2, stride: 2\n",
    "- Up Convolutions (de-convolutions): kernel 2x2\n",
    "- Skip connections (ähnlich zum ResNet)\n",
    "\n",
    "### Dimensionen von den skip connections\n",
    "Die untere Skizze bezeichnet die grauen Pfeile mit \"crop and copy\". Warum nicht nur einfan nur kopieren ? \n",
    "\n",
    "Hint: Dimensionen...\n",
    "\n",
    "Kann man es auch anders lösen, wenn ja wie?\n",
    "\n",
    "## Features\n",
    "- je tiefer in der Architektur desto größer das \"Receptive Field\" (ConvNets)\n",
    "- nur geringer verlust von Information aka low level features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](U-Net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wie implementiert man sowas ?\n",
    "Breche die einzelnen Bestandteile in kleinere runter und implementiere zuerst die \"Kleinigkeiten\", arbeite dich somit bis zum vollständigen UNet. \n",
    "-> Bottom up approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Concatenate, Conv2DTranspose, Dropout, Layer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, activation='relu', padding='same')(inputs)\n",
    "    x = Conv2D(num_filters, 3, activation='relu', padding='same')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeLayer(Layer):  # you can easily change this to be a cropping layer\n",
    "    def __init__(self, target_shape, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.image.resize_with_crop_or_pad(x, self.target_shape[0], self.target_shape[1])\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)  # deconvolution ...\n",
    "    # Check dimensions and scale skip features if needed\n",
    "    if x.shape[1] != skip_features.shape[1] or x.shape[2] != skip_features.shape[2]:\n",
    "        target_shape = x.shape[1:3]\n",
    "        skip_features = ResizeLayer(target_shape=target_shape)(skip_features)\n",
    "    \n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape, out_classes):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    b1 = conv_block(p4, 1024)\n",
    "    \n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = Conv2D(out_classes, 1, activation='sigmoid')(d4)\n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs, name='U-Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET = build_unet((573,572,3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=keras.losses.CategoricalCrossentropy(),  # oder dice loss\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET.summary(line_length=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nun mit Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(ConvBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(num_filters, 3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(num_filters, 3, activation='relu', padding='same')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.conv = ConvBlock(num_filters)\n",
    "        self.pool = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "        return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.up = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')\n",
    "        self.conv = ConvBlock(num_filters)\n",
    "\n",
    "    def call(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = tf.concat([x, skip], axis=-1)\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(tf.keras.Model):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(UNet, self).__init__(**kwargs)\n",
    "        self.enc1 = EncoderBlock(64)\n",
    "        self.enc2 = EncoderBlock(128)\n",
    "        self.enc3 = EncoderBlock(256)\n",
    "        self.enc4 = EncoderBlock(512)\n",
    "        self.center = ConvBlock(1024)\n",
    "        self.dec4 = DecoderBlock(512)\n",
    "        self.dec3 = DecoderBlock(256)\n",
    "        self.dec2 = DecoderBlock(128)\n",
    "        self.dec1 = DecoderBlock(64)\n",
    "        self.out = tf.keras.layers.Conv2D(num_classes, 1, activation='sigmoid', name=\"outs\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        s1, p1 = self.enc1(inputs)\n",
    "        s2, p2 = self.enc2(p1)\n",
    "        s3, p3 = self.enc3(p2)\n",
    "        s4, p4 = self.enc4(p3)\n",
    "\n",
    "        b1 = self.center(p4)\n",
    "\n",
    "        d4 = self.dec4(b1, s4)\n",
    "        d3 = self.dec3(d4, s3)\n",
    "        d2 = self.dec2(d3, s2)\n",
    "        d1 = self.dec1(d2, s1)\n",
    "\n",
    "        outputs = self.out(d1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einblick Formel DiceLoss\n",
    "![alt text](dl.png)\n",
    "\n",
    "## Aber was genau bedeutet das\n",
    "\n",
    "![alt text](dice_vis.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeff(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f))\n",
    "    return dice\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "# ODER\n",
    "\n",
    "\n",
    "class DiceLoss(tf.keras.losses.Loss):  # generalisierte versionen 1-DLCoeff\n",
    "    def __init__(self, name='dice_loss'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "        y_true = tf.reshape(y_true, [-1])\n",
    "        y_pred = tf.reshape(y_pred, [-1])\n",
    "        nominator = 2 * tf.reduce_sum(y_true * y_pred) + self.smooth\n",
    "        denominator = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + self.smooth\n",
    "        dice_loss = 1 - tf.pow((nominator / denominator), 1/self.gama)\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(2)\n",
    "unet.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=DiceLoss(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "unet.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
